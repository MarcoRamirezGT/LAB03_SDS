---
title: "Informe Lab03"
author: "Marco Ramírez, Javier Hernandez"
date: "2023-03-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Laboratorio #3 – Clasificación de Malware

### Exploracion de datos e ingenieria de caracteristicas

```{r}
db<-read.csv('VirusSample.csv')
#Resumen de datos
summary(db)
#Las primeros 5 filas
head(db,5)
#Cantidad de columnas
ncol(db)
#Cantidad de filas
nrow(db)

```

Como se logra observar la base de datos 'VirusSample.csv' tiene `r ncol(db)` columnas y *`r nrow(db)`* filas.

***
Como parte importante para poder clasificar los tipos de virus, se requiere verificar la cantidad de datos de cada uno. 

```{r }
table(db$class)
plot(table(db$class))
```

Como se observa los tipos de virus no se encuentran balanceados, sin embargo, si los balanceamos tendriamos como minimo 1 tipo de virus por categoria, por ende, seguiremos trabajando de esta manera.

Tambien podemos ver las APIS mas repetidas en el dataset:

```{r message=FALSE, warning=FALSE}
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library("SnowballC")
library("wordcloud")
library("tm")

db$api<-gsub(",", " ", db$api)

TextDoc <- Corpus(VectorSource(db$api))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
TextDoc_dtm <- TermDocumentMatrix(TextDoc)
dtm_m <- as.matrix(TextDoc_dtm)
# Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
# Display the top 5 most frequent words
(dtm_d[1:10,])

barplot(dtm_d[1:10,]$freq, las = 2, names.arg = dtm_d[1:10,]$word,
        col ="lightgreen", main ="Las 10 APIS mas repetidas en el dataset",
        ylab = "Word frequencies")

set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))


```

### Preprocesamiento

Como se observo anteriormente los datos no se encuentran balanceados, por ende se requiere balancearlos. Sin embargo, las siguientes variables contienen muy pocos datos por lo cual se decidio juntarlos. Siendo Crypt, Downloader, Dropper, Keylogger, Ransomware, Riskware y Spyware.

```{r }
db<-read.csv('VirusSample.csv')
table(db$class)
db$class[db$class=='Crypt'|db$class=='Downloader' |db$class=='Dropper' |  db$class=='Keylogger'| db$class=='Ransomware'|db$class=='Riskware'| db$class=='Spyware'] <- 'Otro'

table(db$class)
```

### Implementacion
#### SVM

```{r message=FALSE, warning=FALSE}
#Importamos las librerias necesarias
library(e1071)
library(caret)

db$class<-as.factor(db$class)
db$file<-as.factor(db$file)
db$api<-as.factor(db$api)
#SVM
#Indicamos el porcentaje de entranamiento
porcentaje<-0.7

#Datos de entrenamiento y prueba
corte <- sample(nrow(db),nrow(db)*porcentaje)
train<-db[corte,]
test<-db[-corte,]

#Como tenemos muy pocos datos de spyware 
#Creamos el modelo
modelosvm<-svm(class~., data = train, scale = F)
summary(modelosvm)
```

Como se observa se creo el modelo correctamente, indicando que poseemos 13 variables. Con un kernel radial, siendo este el default.

#### Random Forest

```{r message=FALSE, warning=FALSE}
#Importamos las librerias necesarias
library(randomForest)
library(forcats)

#Modificamos la data
new_db <- db[, c("api","class")]
new_db$new_api <- fct_lump(new_db$api, n = 50, other_level = "Otros")
head(new_db, 5)
summary(new_db)

#Indicamos el porcentaje de entranamiento
porcentaje<-0.7

#Datos de entrenamiento y prueba
corte2 <- sample(nrow(new_db),nrow(new_db)*porcentaje)
train2<-new_db[corte2,]
test2<-new_db[-corte2,]

#Creamos el modelo
#modelosvm<-svm(class~., data = train, scale = F)
#summary(modelosvm)
modelo_rf <- randomForest(class ~ new_api, data = train2, ntree = 500)
print(modelo_rf)

#Mostrar el arbol generado por el modelo
library(rpart.plot)
attach(train2)

#Obtener árbol del modelo
arbol_rf <- randomForest::getTree(modelo_rf, k = 1)

#Convertir el árbol de randomForest en un objeto rpart
arbol_rpart <- rpart::rpart(
  formula = formula(modelo_rf),
  data = modelo_rf$forest$x,
  method = "class",
  control = rpart::rpart.control(cp = 0.001)
)

#Graficar el árbol con rpart.plot
rpart.plot::rpart.plot(
  arbol_rpart,
  extra = 1,
  under = TRUE,
  box.palette = "Greens",
  branch.lty = 3,
  nn = TRUE
)
#m1<-rpart(class ~ ., data = train2)
#rpart.plot(m1, type = 3, digits = 3, fallen.leaves = TRUE)
```

Se puede observar que el modelo fue creado de manera correcta y que tiene una estimación OOB de la tasa de error de un 13.74%. Esto significa que ese porcentaje es el porcentaje de error o de equivocación del método OBB que evalua la precisión del modelo, y es bueno ya que es un porcentaje bajo.

### Precision de los modelos
#### SVM

```{r message=FALSE, warning=FALSE}
#Modelos
#SVM
predi<-predict(modelosvm,test[,1:2])
confusionMatrix(test$class,predi)
```

Se observa que el primer modelo tiene un accuracy o una exactitud de 0.6264 lo que significa que el 62.64% de los datos arrojados por la matriz son cercanos o idénticos a los datos reales.

Además, la mayoría de clases tienen un specificity o especificidad mayor a 0.94, lo que significa que el modelo acierta más del 94% de los casos negativos. Es decir, esta métrica pone en relación la cantidad de casos negativos detectados con la cantidad de casos negativos totales.

#### Random Forest

```{r message=FALSE, warning=FALSE}
predi2<-predict(modelo_rf,test2[,1:3])
confusionMatrix(test2$class,predi2)
```

Se observa que el segundo modelo tiene un accuracy o una exactitud de 0.8571 lo que significa que el 85.71% de los datos arrojados por la matriz son cercanos o idénticos a los datos reales.

Además, la mayoría de clases tienen un sensitivity o sensibilidad mayor a 0.86, esto quiere decir que el modelo acierta más del 86% de los casos positivos. Es decir, esta métrica determina la capacidad del algoritmo de detectar los casos positivos.

También, la mayoría de clases tienen un specificity o especificidad mayor a 0.97, por lo que sabemos que el modelo acierta más del 97% de los casos negativos. Y por último, la mayoría de clases tienen un balanced accuracy o exactitud equilibrada mayor a 0.84.

Finalmente, mencionar que en el caso del modelo SVM no se obtuvieron mejores métricas que las obtenidas en el artículo y en el caso del RF sí, se obtuvo una pequeña mejora en las métricas.
